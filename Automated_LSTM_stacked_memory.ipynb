{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Stacked with Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import useful libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define helper functions\n",
    "def transform_data(data, look_back):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back - 1):\n",
    "        X.append(data[i:(i+look_back),0])\n",
    "        y.append(data[i+look_back,0])\n",
    "    return np.array(X),np.array(y)\n",
    "\n",
    "def divisorGenerator(n):\n",
    "    divisors = []\n",
    "    for i in range(1, int(math.sqrt(n) + 1)):\n",
    "        if n % i == 0:\n",
    "            yield i\n",
    "            if i*i != n:\n",
    "                divisors.append(n / i)\n",
    "    return divisors\n",
    "\n",
    "def get_common_divisor(num1,num2):\n",
    "    s1 = set(divisorGenerator(num1))\n",
    "    s2 = set(divisorGenerator(num2))\n",
    "    \n",
    "    return list(s1.intersection(s2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_file(filename,stock_parameter):\n",
    "    df = pd.read_csv('./'+filename+'.csv',usecols=[stock_parameter])\n",
    "    df = df[::-1]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to create custom dataset based on the lookback value\n",
    "def create_dataset(data,look_back):\n",
    "    train_size = int(len(data)*0.8)\n",
    "    test_size = len(data) - train_size\n",
    "    train_set = data[0:train_size,:]\n",
    "    test_set = data[train_size:len(data),:]    \n",
    "    \n",
    "    X_train, y_train = transform_data(train_set, look_back)\n",
    "    X_test, y_test = transform_data(test_set, look_back)\n",
    "    \n",
    "    # reshape input to be [samples, time steps, features]\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "    \n",
    "    batch_size = get_common_divisor(X_train.shape[0],X_test.shape[0])[-1]\n",
    "                        \n",
    "    return X_train,y_train,X_test,y_test,batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_time_steps(data,X_train,y_train,X_test,y_test,batch_size,epoch,look_back,no_of_days,filename,stock_parameter,scaler):\n",
    "    # creating the LSTM\n",
    "    algorithm = \"lstm_stacked_memory\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4,\n",
    "               batch_input_shape = (batch_size,look_back,1),\n",
    "               stateful = True,\n",
    "               return_sequences = True))\n",
    "    model.add(LSTM(4,\n",
    "                   batch_input_shape = (batch_size,look_back,1),\n",
    "                   stateful = True))\n",
    "    model.add(Dense(\n",
    "        output_dim = 1\n",
    "    ))\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "    \n",
    "    start_time = time.clock()\n",
    "    \n",
    "    # train the model\n",
    "    for i in range(epoch):\n",
    "        model.fit(X_train,\n",
    "                  y_train,\n",
    "                  epochs = 1,\n",
    "                  batch_size = batch_size, \n",
    "                  verbose = 2,\n",
    "                  shuffle = False\n",
    "                 )\n",
    "        model.reset_states()\n",
    "    time_taken = int(time.clock() - start_time)\n",
    " \n",
    "    predicted_train = model.predict(X_train,\n",
    "                                   batch_size = batch_size)\n",
    "    model.reset_states()\n",
    "    \n",
    "    # predict using the model\n",
    "    predicted_test = model.predict(X_test,\n",
    "                                  batch_size=batch_size)\n",
    "    predicted_train = scaler.inverse_transform(predicted_train)\n",
    "    y_train_org = scaler.inverse_transform([y_train])\n",
    "\n",
    "    predicted_test = scaler.inverse_transform(predicted_test)\n",
    "    y_test_org = scaler.inverse_transform([y_test])\n",
    "    \n",
    "    train_score = round(math.sqrt(mean_squared_error(y_train_org[0],predicted_train[:,0])),2)\n",
    "    test_score = round(math.sqrt(mean_squared_error(y_test_org[0],predicted_test[:,0])),2)\n",
    "\n",
    "    # save values to log file\n",
    "    with open(\"./logs_stacked.csv\", \"a\") as myfile:\n",
    "        myfile.write('\\n'+algorithm+','\n",
    "                     +str(no_of_days)+','\n",
    "                     +str(X_test.shape[0])+','\n",
    "                     +str(look_back)+','\n",
    "                     +str(epoch)+','\n",
    "                     +str(batch_size)+','\n",
    "                     +str(train_score)+','\n",
    "                     +str(test_score)+','\n",
    "                     +str(time_taken)+','\n",
    "                     +str(filename)+','\n",
    "                     +str(stock_parameter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search over LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    epoch_array = [10,20,30,40]\n",
    "    loop_back_array = [3,7,14,28]\n",
    "    no_of_days_array = [300,600,900]\n",
    "    filename = \"BABA\"\n",
    "    stock_parameter = \"close\"\n",
    "    \n",
    "    file_loaded = load_file(filename,stock_parameter)\n",
    "    \n",
    "    # Conduct Grid Search over the LSTM model and save the results to log file\n",
    "    for x in list(itertools.product(epoch_array, loop_back_array,no_of_days_array)):\n",
    "        print(\"---------------------------\",x,\"--------------------------\")\n",
    "        df = file_loaded.iloc[-x[2]:]\n",
    "        data = df.values\n",
    "        data = data.astype('float32')\n",
    "        \n",
    "        # Apply min max scaling over the data\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        data = scaler.fit_transform(data)\n",
    "        \n",
    "        # Create custom dataset\n",
    "        X_train,y_train,X_test,y_test,batch_size = create_dataset(data,x[1])\n",
    "        \n",
    "        lstm_time_steps(data,\n",
    "                        X_train,\n",
    "                        y_train,\n",
    "                        X_test,\n",
    "                        y_test,\n",
    "                        batch_size,\n",
    "                        x[0], #ephoch\n",
    "                        x[1], #loopback\n",
    "                        x[2], #no_of_days\n",
    "                        filename,\n",
    "                        stock_parameter,\n",
    "                        scaler)\n",
    "    # save the values in the log file    \n",
    "    f = open(\"./logs_stacked.csv\", \"r\")\n",
    "    csv_f = csv.reader(f)\n",
    "    for row in csv_f:\n",
    "        print('{:<25} {:<10} {:<10} {:<8} {:<7} {:<10} {:<10} {:<10} {:<10} {:<9} {:<7}'.format(*row))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
