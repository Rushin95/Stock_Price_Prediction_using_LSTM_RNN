{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM with sliding window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import important libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "def transform_data(data, look_back):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back - 1):\n",
    "        X.append(data[i:(i+look_back),0])\n",
    "        y.append(data[i+look_back,0])\n",
    "    return np.array(X),np.array(y)\n",
    "\n",
    "def divisorGenerator(n):\n",
    "    divisors = []\n",
    "    for i in range(1, int(math.sqrt(n) + 1)):\n",
    "        if n % i == 0:\n",
    "            yield i\n",
    "            if i*i != n:\n",
    "                divisors.append(n / i)\n",
    "    return divisors\n",
    "\n",
    "def get_common_divisor(num1,num2):\n",
    "    s1 = set(divisorGenerator(num1))\n",
    "    s2 = set(divisorGenerator(num2))\n",
    "    \n",
    "    return list(s1.intersection(s2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_file(filename,stock_parameter):\n",
    "    df = pd.read_csv('./'+filename+'.csv',usecols=[stock_parameter])\n",
    "    df = df[::-1]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(data,look_back):\n",
    "    train_size = int(len(data)*0.8)\n",
    "    test_size = len(data) - train_size\n",
    "    train_set = data[0:train_size,:]\n",
    "    test_set = data[train_size:len(data),:]    \n",
    "    \n",
    "    X_train, y_train = transform_data(train_set, look_back)\n",
    "    X_test, y_test = transform_data(test_set, look_back)\n",
    "    \n",
    "    # reshape input to be [samples, time steps, features]\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0],1,X_train.shape[1]))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0],1,X_test.shape[1]))\n",
    "                        \n",
    "    batch_size = get_common_divisor(X_train.shape[0],X_test.shape[0])[-1]\n",
    "                        \n",
    "    return X_train,y_train,X_test,y_test,batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to create custom dataset based on the lookback value\n",
    "def lstm_time_steps(data,X_train,y_train,X_test,y_test,batch_size,epoch,look_back,no_of_days,filename,stock_parameter,scaler):\n",
    "    # creating the LSTM\n",
    "    algorithm = \"lstm_lookback_window\"\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4,\n",
    "                   input_shape = (1, look_back)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "    \n",
    "    # train the model\n",
    "    start_time = time.clock()\n",
    "    model.fit(X_train,\n",
    "              y_train,\n",
    "              epochs = epoch,\n",
    "              batch_size = batch_size, \n",
    "              verbose = 2)\n",
    "    time_taken = int(time.clock() - start_time)\n",
    "    \n",
    "    # do predictions\n",
    "    predicted_train = model.predict(X_train)\n",
    "    predaicted_test = model.predict(X_test)\n",
    "    predicted_train = scaler.inverse_transform(predicted_train)\n",
    "    y_train_org = scaler.inverse_transform([y_train])\n",
    "\n",
    "    predicted_test = scaler.inverse_transform(predicted_test)\n",
    "    y_test_org = scaler.inverse_transform([y_test])\n",
    "    \n",
    "    train_score = round(math.sqrt(mean_squared_error(y_train_org[0],predicted_train[:,0])),2)\n",
    "    test_score = round(math.sqrt(mean_squared_error(y_test_org[0],predicted_test[:,0])),2)\n",
    "    \n",
    "    with open(\"./logs_sliding.csv\", \"a\") as myfile:\n",
    "        myfile.write('\\n'+algorithm+','\n",
    "                     +str(no_of_days)+','\n",
    "                     +str(X_test.shape[0])+','\n",
    "                     +str(look_back)+','\n",
    "                     +str(epoch)+','\n",
    "                     +str(batch_size)+','\n",
    "                     +str(train_score)+','\n",
    "                     +str(test_score)+','\n",
    "                     +str(time_taken)+','\n",
    "                     +str(filename)+','\n",
    "                     +str(stock_parameter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search over LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    epoch_array = [10,20,30,40]\n",
    "    loop_back_array = [3,7,14,28]\n",
    "    no_of_days_array = [300,600,900]\n",
    "\n",
    "    filename = \"BABA\"\n",
    "    stock_parameter = \"close\"\n",
    "    \n",
    "    file_loaded = load_file(filename,stock_parameter)\n",
    "    \n",
    "    # Conduct Grid Search over the LSTM model and save the results to log file\n",
    "    for x in list(itertools.product(epoch_array, loop_back_array,no_of_days_array)):\n",
    "        print(\"---------------------------\",x,\"--------------------------\")\n",
    "        df = file_loaded.iloc[-x[2]:]\n",
    "        data = df.values\n",
    "        data = data.astype('float32')    \n",
    "\n",
    "        # Apply min max scaling over the data\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        data = scaler.fit_transform(data)\n",
    "        \n",
    "        # Create custom dataset\n",
    "        X_train,y_train,X_test,y_test,batch_size = create_dataset(data,x[1])\n",
    "        \n",
    "        lstm_time_steps(data,\n",
    "                        X_train,\n",
    "                        y_train,\n",
    "                        X_test,\n",
    "                        y_test,\n",
    "                        batch_size,\n",
    "                        x[0], #ephoch\n",
    "                        x[1], #loopback\n",
    "                        x[2], #no_of_days\n",
    "                        filename,\n",
    "                        stock_parameter,\n",
    "                        scaler)\n",
    "        \n",
    "    f = open(\"./logs_sliding.csv\", \"r\")\n",
    "    csv_f = csv.reader(f)\n",
    "    for row in csv_f:\n",
    "        print('{:<25} {:<10} {:<10} {:<8} {:<7} {:<10} {:<10} {:<10} {:<10} {:<9} {:<7}'.format(*row))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
